<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Plonky3 recursion book</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Plonky3 recursion book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="plonky3-recursion"><a class="header" href="#plonky3-recursion">Plonky3 Recursion</a></h1>
<p>This book is the user guide for <strong>Plonky3 recursion</strong>, an independent project providing native recursive STARK verification for <a href="https://github.com/Plonky3/Plonky3">Plonky3</a>.</p>
<p>The library lets you verify Plonky3 STARK proofs inside circuits, chain recursive layers to compress proof size, and aggregate independent proofs into a single attestation. It is built entirely on Plonky3's own STARK primitives — no separate plonkish SNARK wrapper.</p>
<h2 id="what-this-book-covers"><a class="header" href="#what-this-book-covers">What this book covers</a></h2>
<ul>
<li><strong><a href="./getting_started/introduction.html">Getting Started</a></strong> — Motivation, design philosophy, and a quick start guide with working examples.</li>
<li><strong><a href="./user_guide/api.html">User Guide</a></strong> — The unified recursion API, aggregation, configuration, public inputs, integration into your project, and the low-level API for advanced use cases.</li>
<li><strong><a href="./architecture_and_internals/construction.html">Architecture &amp; Internals</a></strong> — How the fixed recursive verifier is built: the execution IR, witness table, operation-specific chips, circuit building pipeline, trace generation, and Poseidon2-based hashing.</li>
<li><strong><a href="./advanced_topics/scaling.html">Advanced Topics</a></strong> — Scaling strategies for variable-length inputs, performance tuning, soundness considerations, and debugging tools.</li>
<li><strong><a href="./appendix/benchmark.html">Appendix</a></strong> — Benchmarks, roadmap, and glossary.</li>
</ul>
<h2 id="quick-links"><a class="header" href="#quick-links">Quick links</a></h2>
<ul>
<li><strong>Source</strong>: <a href="https://github.com/Plonky3/Plonky3-recursion">github.com/Plonky3/Plonky3-recursion</a></li>
<li><strong>API docs</strong>: <code>cargo doc --open</code></li>
<li><strong>Examples</strong>: <code>recursion/examples/</code> — recursive Fibonacci, Keccak, and 2-to-1 aggregation</li>
<li><strong>License</strong>: Dual MIT / Apache-2.0</li>
</ul>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><a href="https://github.com/Plonky3/Plonky3">Plonky3</a> offers a comprehensive toolbox of cryptographic building blocks: hash functions, finite fields, and polynomial commitment schemes, ... to build tailored STARK proof systems. However, its adoption has been limited by the lack of native recursion, to allow arbitrary program execution replication in proof systems and to alleviate proof sizes and related on-chain verification costs.</p>
<p>This project aims at addressing this limitation, by proposing a minimal, fixed recursive verifier for Plonky3, which conceptual simplicity allows for blazing fast recursion performance. A key distinction with its predecessor <a href="https://github.com/0xPolygonZero/plonky2">plonky2</a>, is that rather than wrapping a STARK proof in a separate plonkish SNARK, the Plonky3 recursion stack itself is built using Plonky3’s STARK primitives.</p>
<p>The source code is open-source, available at <a href="https://github.com/Plonky3/Plonky3-recursion">Plonky3 recursion</a> and dual-licensed MIT/APACHE-2.</p>
<p><em><strong>NOTE</strong></em>: <em>This project is under active development, unaudited and as such not ready for production use. We welcome all external contributors who would like to support the development effort.</em></p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<h2 id="requirements"><a class="header" href="#requirements">Requirements</a></h2>
<ul>
<li>Rust stable (edition 2024)</li>
<li>For best performance: <code>RUSTFLAGS="-Ctarget-cpu=native"</code></li>
</ul>
<h2 id="add-the-dependency"><a class="header" href="#add-the-dependency">Add the dependency</a></h2>
<p>Plonky3-recursion is not yet published on crates.io. Add it as a git dependency:</p>
<pre><code class="language-toml">[dependencies]
p3-recursion = { git = "https://github.com/Plonky3/Plonky3-recursion", package = "p3-recursion" }
</code></pre>
<p>You will also need Plonky3 crates for fields, STARKs, and hashing. The recursion library re-exports what it needs, but your base prover setup will require direct Plonky3 dependencies.</p>
<h2 id="minimal-example"><a class="header" href="#minimal-example">Minimal example</a></h2>
<p>The fastest way to verify a proof recursively:</p>
<pre><code class="language-rust ignore">use p3_recursion::{
    FriRecursionBackend, ProveNextLayerParams, RecursionInput,
    build_and_prove_next_layer, BatchOnly, Poseidon2Config,
};

// 1. You already have a Plonky3 STARK proof (uni-stark or batch-stark).
//    Wrap it in a RecursionInput.
let input = RecursionInput::UniStark {
    proof: &amp;base_proof,
    air: &amp;my_air,
    public_inputs: public_values.clone(),
    preprocessed_commit: None,
};

// 2. Create the FRI backend with a Poseidon2 config matching your field.
let backend = FriRecursionBackend::&lt;16, 8&gt;::new(Poseidon2Config::KoalaBearD4Width16);

// 3. Prove. This builds the verifier circuit, runs it, and produces a batch-STARK proof.
let params = ProveNextLayerParams::default();
let output = build_and_prove_next_layer::&lt;_, _, _, 4&gt;(
    &amp;input, &amp;config, &amp;backend, &amp;params,
)?;

// 4. Chain further layers by converting the output back to an input.
let next_input = output.into_recursion_input::&lt;BatchOnly&gt;();
let output_2 = build_and_prove_next_layer::&lt;_, _, _, 4&gt;(
    &amp;next_input, &amp;config, &amp;backend, &amp;params,
)?;</code></pre>
<p>The config (<code>&amp;config</code>) must implement <code>FriRecursionConfig</code>. See the <a href="getting_started/./integration.html">Integration Guide</a> for how to set this up, or the <a href="getting_started/./examples.html">Examples</a> for complete working code.</p>
<h2 id="running-the-examples"><a class="header" href="#running-the-examples">Running the examples</a></h2>
<p>Three examples ship with the library:</p>
<pre><code class="language-bash"># Recursive Keccak (uni-STARK base proof)
cargo run --release --example recursive_keccak -- --field koala-bear --num-hashes 100

# Recursive Fibonacci (batch-STARK base proof built with CircuitBuilder)
cargo run --release --example recursive_fibonacci -- --field koala-bear --n 1000

# 2-to-1 aggregation (binary tree of proofs)
cargo run --release --example recursive_aggregation -- --field koala-bear
</code></pre>
<p>Add <code>--features parallel</code> and <code>RUSTFLAGS="-Ctarget-cpu=native"</code> for production-level performance.</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<p>This section walks through the three provided examples to illustrate common recursion patterns.</p>
<h2 id="recursive-keccak--verifying-a-uni-stark-proof"><a class="header" href="#recursive-keccak--verifying-a-uni-stark-proof">Recursive Keccak — verifying a uni-STARK proof</a></h2>
<p><strong>Source</strong>: <code>recursion/examples/recursive_keccak.rs</code></p>
<p>This example starts from a standard Plonky3 uni-STARK proof of the Keccak AIR, then recursively verifies it through multiple layers.</p>
<p><strong>Flow:</strong></p>
<ol>
<li>Generate a Keccak trace and prove it with <code>p3_uni_stark::prove</code>.</li>
<li>Wrap the resulting <code>Proof&lt;SC&gt;</code> in a <code>RecursionInput::UniStark</code>.</li>
<li>Call <code>build_and_prove_next_layer</code> — this builds a verification circuit that checks the Keccak proof, runs it, and produces a batch-STARK proof.</li>
<li>For subsequent layers, convert the output with <code>output.into_recursion_input::&lt;BatchOnly&gt;()</code> and repeat.</li>
</ol>
<p>The key point: the first recursive layer handles a <strong>uni-STARK</strong> proof (potentially large, depending on the AIR width). After that, every layer verifies the previous layer's <strong>batch-STARK</strong> proof, which has a predictable, smaller structure. This is why layer 1 is typically slower than layers 2+.</p>
<pre><code class="language-bash">cargo run --release --example recursive_keccak -- \
    --field koala-bear --num-hashes 1000 --num-recursive-layers 3
</code></pre>
<h2 id="recursive-fibonacci--verifying-a-batch-stark-proof"><a class="header" href="#recursive-fibonacci--verifying-a-batch-stark-proof">Recursive Fibonacci — verifying a batch-STARK proof</a></h2>
<p><strong>Source</strong>: <code>recursion/examples/recursive_fibonacci.rs</code></p>
<p>This example builds a Fibonacci circuit from scratch using <code>CircuitBuilder</code>, proves it with <code>BatchStarkProver</code>, then recurses.</p>
<p><strong>Flow:</strong></p>
<ol>
<li>Build the circuit: <code>CircuitBuilder::new()</code>, add constants, public inputs, arithmetic, <code>connect</code>, <code>build</code>.</li>
<li>Run and prove the base circuit with <code>BatchStarkProver</code>.</li>
<li>Wrap the output in <code>RecursionOutput</code> (since it's already a batch proof), then use <code>into_recursion_input::&lt;BatchOnly&gt;()</code>.</li>
<li>Call <code>build_and_prove_next_layer</code> in a loop for each recursive layer.</li>
</ol>
<p>This example demonstrates how to use the <code>CircuitBuilder</code> for your own computations and then feed the resulting proof into the recursion pipeline.</p>
<pre><code class="language-bash">cargo run --release --example recursive_fibonacci -- \
    --field koala-bear --n 10000 --num-recursive-layers 3
</code></pre>
<h2 id="recursive-aggregation--2-to-1-proof-merging"><a class="header" href="#recursive-aggregation--2-to-1-proof-merging">Recursive Aggregation — 2-to-1 proof merging</a></h2>
<p><strong>Source</strong>: <code>recursion/examples/recursive_aggregation.rs</code></p>
<p>This example produces multiple independent base proofs and aggregates them pairwise in a binary tree.</p>
<p><strong>Flow:</strong></p>
<ol>
<li>Produce <code>2^depth</code> independent base proofs (each proving a different constant).</li>
<li>At each tree level, pair up proofs and call <code>build_and_prove_aggregation_layer</code> on each pair.</li>
<li>Repeat until a single root proof remains.</li>
</ol>
<p>The aggregation circuit verifies <strong>two</strong> proofs in a single circuit — left and right children — producing one output proof. The two inputs may be different kinds of <code>RecursionInput</code> (e.g., one <code>UniStark</code> and one <code>BatchStark</code>), though in this example they are all <code>BatchStark</code>.</p>
<pre><code class="language-bash"># 4 base proofs, 2 aggregation levels
cargo run --release --example recursive_aggregation -- \
    --field koala-bear --num-recursive-layers 2
</code></pre>
<h2 id="common-patterns-across-examples"><a class="header" href="#common-patterns-across-examples">Common patterns across examples</a></h2>
<p>All three examples share the same setup pattern:</p>
<ol>
<li>
<p><strong>Config wrapper</strong>: A <code>ConfigWithFriParams</code> struct that wraps a <code>StarkConfig</code> and adds <code>FriVerifierParams</code>. It implements <code>StarkGenericConfig</code> (by delegating) and <code>FriRecursionConfig</code>.</p>
</li>
<li>
<p><strong>Backend creation</strong>: <code>FriRecursionBackend::&lt;WIDTH, RATE&gt;::new(poseidon2_config)</code>.</p>
</li>
<li>
<p><strong>Table packing</strong>: Adjusted per layer — the first layer may need different packing than subsequent layers because the verification circuit has a different shape.</p>
</li>
<li>
<p><strong>Verification after proving</strong>: Each example verifies the proof it just produced, using <code>BatchStarkProver::verify_all_tables</code>.</p>
</li>
</ol>
<p>See the <a href="getting_started/./integration.html">Integration Guide</a> for how to adapt this pattern to your own project.</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="unified-recursion-api"><a class="header" href="#unified-recursion-api">Unified Recursion API</a></h1>
<p>The library exposes a unified API that handles both uni-STARK and batch-STARK proofs through a single set of entry points.</p>
<h2 id="core-types"><a class="header" href="#core-types">Core types</a></h2>
<h3 id="recursioninput"><a class="header" href="#recursioninput"><code>RecursionInput</code></a></h3>
<p>Wraps the proof to verify at each recursion step:</p>
<pre><code class="language-rust ignore">pub enum RecursionInput&lt;'a, SC, A&gt; {
    /// A single-instance STARK proof (e.g. from p3-uni-stark).
    UniStark {
        proof: &amp;'a Proof&lt;SC&gt;,
        air: &amp;'a A,
        public_inputs: Vec&lt;Val&lt;SC&gt;&gt;,
        preprocessed_commit: Option&lt;Commitment&gt;,
    },
    /// A batch STARK proof (e.g. from p3-batch-stark or circuit-prover).
    BatchStark {
        proof: &amp;'a BatchStarkProof&lt;SC&gt;,
        common_data: &amp;'a CommonData&lt;SC&gt;,
        table_public_inputs: Vec&lt;Vec&lt;Val&lt;SC&gt;&gt;&gt;,
    },
}</code></pre>
<p>Use <code>UniStark</code> when verifying an external Plonky3 proof (e.g. Keccak AIR). Use <code>BatchStark</code> when verifying a proof produced by this library's own prover.</p>
<h3 id="recursionoutput"><a class="header" href="#recursionoutput"><code>RecursionOutput</code></a></h3>
<p>The output of one recursion step:</p>
<pre><code class="language-rust ignore">pub struct RecursionOutput&lt;SC&gt;(pub BatchStarkProof&lt;SC&gt;, pub CircuitProverData&lt;SC&gt;);</code></pre>
<p>Contains the batch-STARK proof and the prover data needed for further chaining. Convert it to a <code>RecursionInput</code> for the next layer:</p>
<pre><code class="language-rust ignore">let next_input = output.into_recursion_input::&lt;BatchOnly&gt;();</code></pre>
<p>The <code>BatchOnly</code> marker type satisfies the <code>RecursiveAir</code> bound without carrying any AIR data — it's a no-op used when the next layer only needs to verify the recursive batch proof.</p>
<h3 id="provenextlayerparams"><a class="header" href="#provenextlayerparams"><code>ProveNextLayerParams</code></a></h3>
<p>Controls the proving pipeline:</p>
<pre><code class="language-rust ignore">pub struct ProveNextLayerParams {
    pub table_packing: TablePacking,
    pub use_poseidon2_in_circuit: bool,
}</code></pre>
<ul>
<li><code>table_packing</code>: How to distribute operations across table lanes. See <a href="user_guide/./configuration.html#table-packing">Configuration</a>.</li>
<li><code>use_poseidon2_in_circuit</code>: Whether to register the Poseidon2 non-primitive table. Should be <code>true</code> for FRI verification.</li>
</ul>
<h2 id="entry-points"><a class="header" href="#entry-points">Entry points</a></h2>
<h3 id="build_and_prove_next_layer"><a class="header" href="#build_and_prove_next_layer"><code>build_and_prove_next_layer</code></a></h3>
<p>The simplest way to prove one recursion step. Builds the verifier circuit, runs it, and proves it in one call:</p>
<pre><code class="language-rust ignore">let output = build_and_prove_next_layer::&lt;SC, A, B, D&gt;(
    &amp;input, &amp;config, &amp;backend, &amp;params,
)?;</code></pre>
<h3 id="prove_next_layer"><a class="header" href="#prove_next_layer"><code>prove_next_layer</code></a></h3>
<p>For better performance in production, separate circuit building from proving. The circuit only needs to be built once if the proof shape doesn't change between invocations:</p>
<pre><code class="language-rust ignore">// Build once
let (circuit, verifier_result) = build_next_layer_circuit(&amp;input, &amp;config, &amp;backend)?;

// Prove (can be called multiple times with different inputs of the same shape)
let output = prove_next_layer::&lt;SC, A, B, D&gt;(
    &amp;input, circuit, &amp;verifier_result, &amp;config, &amp;backend, &amp;params,
)?;</code></pre>
<h3 id="build_and_prove_aggregation_layer"><a class="header" href="#build_and_prove_aggregation_layer"><code>build_and_prove_aggregation_layer</code></a></h3>
<p>Verifies two proofs in a single circuit. The two inputs can be different <code>RecursionInput</code> variants:</p>
<pre><code class="language-rust ignore">let output = build_and_prove_aggregation_layer::&lt;SC, A1, A2, B, D&gt;(
    &amp;left, &amp;right, &amp;config, &amp;backend, &amp;params,
)?;</code></pre>
<h3 id="prove_aggregation_layer"><a class="header" href="#prove_aggregation_layer"><code>prove_aggregation_layer</code></a></h3>
<p>The split build/prove variant for aggregation:</p>
<pre><code class="language-rust ignore">let (circuit, (left_result, right_result)) =
    build_aggregation_layer_circuit(&amp;left, &amp;right, &amp;config, &amp;backend)?;

let output = prove_aggregation_layer::&lt;SC, A1, A2, B, D&gt;(
    &amp;left, &amp;right, &amp;left_result, &amp;right_result,
    circuit, &amp;config, &amp;backend, &amp;params,
)?;</code></pre>
<h2 id="recursion-loop-pattern"><a class="header" href="#recursion-loop-pattern">Recursion loop pattern</a></h2>
<p>A typical recursion loop looks like this:</p>
<pre><code class="language-rust ignore">let backend = FriRecursionBackend::&lt;16, 8&gt;::new(Poseidon2Config::KoalaBearD4Width16);

// Layer 1: verify the base proof
let input = RecursionInput::UniStark { proof: &amp;base_proof, air: &amp;my_air, .. };
let mut output = build_and_prove_next_layer::&lt;_, _, _, 4&gt;(&amp;input, &amp;config, &amp;backend, &amp;params)?;

// Layers 2..N: verify the previous recursive proof
for _ in 2..=num_layers {
    let input = output.into_recursion_input::&lt;BatchOnly&gt;();
    output = build_and_prove_next_layer::&lt;_, _, _, 4&gt;(&amp;input, &amp;config, &amp;backend, &amp;params)?;
}</code></pre>
<p>After enough layers, the recursive proof reaches a steady-state size — further layers don't meaningfully change the proof dimensions.</p>
<h2 id="type-parameter-d"><a class="header" href="#type-parameter-d">Type parameter <code>D</code></a></h2>
<p>The const generic <code>D</code> is the extension field degree. For all currently supported fields (BabyBear, KoalaBear), use <code>D = 4</code>.</p>
<h2 id="frirecursionbackend"><a class="header" href="#frirecursionbackend">FriRecursionBackend</a></h2>
<p>The <code>FriRecursionBackend&lt;WIDTH, RATE&gt;</code> implements <code>PcsRecursionBackend</code> for FRI-based configs. It handles:</p>
<ul>
<li>Enabling Poseidon2 on the circuit builder</li>
<li>Building the verifier circuit (delegating to <code>verify_p3_uni_proof_circuit</code> or <code>verify_p3_batch_proof_circuit</code>)</li>
<li>Packing public inputs</li>
<li>Setting Merkle path private data</li>
</ul>
<p>Create one with:</p>
<pre><code class="language-rust ignore">let backend = FriRecursionBackend::&lt;16, 8&gt;::new(Poseidon2Config::KoalaBearD4Width16);</code></pre>
<p><code>WIDTH</code> and <code>RATE</code> are the Poseidon2 permutation parameters (typically 16 and 8 for 32-bit fields).</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="aggregation"><a class="header" href="#aggregation">Aggregation</a></h1>
<p>The library supports 2-to-1 recursive aggregation: verifying two proofs inside a single circuit and producing one output proof. This enables binary tree aggregation of independent computations.</p>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How it works</a></h2>
<p>An aggregation circuit contains two verifier sub-circuits sharing the same <code>CircuitBuilder</code>. Both verifications use the same Poseidon2 table and primitive chips. The combined circuit is then proved as a single batch-STARK.</p>
<pre><code>       ┌────────────────────────┐
       │   Aggregation Circuit  │
       │                        │
       │  ┌──────┐  ┌──────┐   │
       │  │Verify│  │Verify│   │
       │  │ left │  │right │   │
       │  └──────┘  └──────┘   │
       │                        │
       └────────────────────────┘
                  │
            One batch-STARK
               proof out
</code></pre>
<p>The left and right inputs are independent — they can be different <code>RecursionInput</code> variants (e.g., one <code>UniStark</code> and one <code>BatchStark</code>), and they can verify different AIRs entirely.</p>
<h2 id="api"><a class="header" href="#api">API</a></h2>
<pre><code class="language-rust ignore">use p3_recursion::{
    build_and_prove_aggregation_layer, RecursionInput, BatchOnly,
    FriRecursionBackend, ProveNextLayerParams, Poseidon2Config,
};

let left = RecursionInput::UniStark {
    proof: &amp;proof_a, air: &amp;air_a, public_inputs: pis_a.clone(), preprocessed_commit: None,
};
let right = RecursionInput::UniStark {
    proof: &amp;proof_b, air: &amp;air_b, public_inputs: pis_b.clone(), preprocessed_commit: None,
};

let backend = FriRecursionBackend::&lt;16, 8&gt;::new(Poseidon2Config::KoalaBearD4Width16);
let params = ProveNextLayerParams::default();

let output = build_and_prove_aggregation_layer::&lt;_, _, _, _, 4&gt;(
    &amp;left, &amp;right, &amp;config, &amp;backend, &amp;params,
)?;</code></pre>
<p>The output is a regular <code>RecursionOutput</code> and can be fed into further aggregation or recursion layers via <code>into_recursion_input::&lt;BatchOnly&gt;()</code>.</p>
<h2 id="tree-aggregation"><a class="header" href="#tree-aggregation">Tree aggregation</a></h2>
<p>To aggregate N independent proofs, arrange them as leaves of a binary tree and aggregate pairwise, bottom up:</p>
<pre><code>Level 0 (leaves):  P0   P1   P2   P3
                    \  /      \  /
Level 1:           Agg01    Agg23
                      \    /
Level 2 (root):      Root
</code></pre>
<p>At each level, every pair is aggregated independently — this is embarrassingly parallel.</p>
<pre><code class="language-rust ignore">let mut proofs: Vec&lt;RecursionOutput&lt;SC&gt;&gt; = base_proofs;

while proofs.len() &gt; 1 {
    let mut next = Vec::new();
    for pair in proofs.chunks(2) {
        let left = pair[0].into_recursion_input::&lt;BatchOnly&gt;();
        let right = pair[1].into_recursion_input::&lt;BatchOnly&gt;();
        let out = build_and_prove_aggregation_layer::&lt;_, _, _, _, 4&gt;(
            &amp;left, &amp;right, &amp;config, &amp;backend, &amp;params,
        )?;
        next.push(out);
    }
    proofs = next;
}
// proofs[0] is the root proof</code></pre>
<h2 id="cost"><a class="header" href="#cost">Cost</a></h2>
<p>An aggregation circuit is roughly twice the size of a single-verification circuit (two verifiers in one circuit). The Poseidon2 table is shared, so the overhead is less than 2x for hash-heavy proofs.</p>
<p>Adjust <code>TablePacking</code> for aggregation circuits — they produce wider traces than single-verification circuits. See <a href="user_guide/./configuration.html#table-packing">Configuration</a> for guidance.</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="configuration"><a class="header" href="#configuration">Configuration</a></h1>
<p>This section covers the parameters you need to choose when setting up recursive verification.</p>
<h2 id="field-selection"><a class="header" href="#field-selection">Field selection</a></h2>
<p>The library currently supports two base fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Modulus</th><th>Bits</th><th>Status</th></tr></thead><tbody>
<tr><td><strong>KoalaBear</strong></td><td><code>0x7F000001</code></td><td>31</td><td>Recommended</td></tr>
<tr><td><strong>BabyBear</strong></td><td><code>0x78000001</code></td><td>31</td><td>Fully supported</td></tr>
</tbody></table>
</div>
<p>All fields support degree-4 binomial extensions (<code>BinomialExtensionField&lt;F, 4&gt;</code>), which is a currently
fixed parameter for the recursion stack, with plans to lift it to a runtime parameter in the future.</p>
<h2 id="fri-parameters"><a class="header" href="#fri-parameters">FRI parameters</a></h2>
<p>FRI parameters control the trade-off between proof size, verifier cost, and security level.</p>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Typical value</th><th>Effect</th></tr></thead><tbody>
<tr><td><code>log_blowup</code></td><td>3</td><td>LDE blowup factor (<code>2^log_blowup</code>). Higher = more redundancy, fewer queries needed.</td></tr>
<tr><td><code>max_log_arity</code></td><td>4</td><td>Maximum folding factor per FRI round (<code>2^max_log_arity</code>). Controls how quickly polynomial degree reduces.</td></tr>
<tr><td><code>log_final_poly_len</code></td><td>5</td><td>Degree of the final polynomial after folding. Smaller = more folding rounds but simpler final check.</td></tr>
<tr><td><code>query_pow_bits</code></td><td>16</td><td>Proof-of-work bits during the query phase. Higher = fewer queries needed for same security.</td></tr>
<tr><td><code>commit_pow_bits</code></td><td>0</td><td>Proof-of-work bits during the commit phase. Usually 0.</td></tr>
<tr><td><code>cap_height</code></td><td>0</td><td>Height at which Merkle trees are truncated for commitments. 0 = single root hash.</td></tr>
</tbody></table>
</div>
<h3 id="security-level"><a class="header" href="#security-level">Security level</a></h3>
<p>The number of FRI queries is derived as:</p>
<pre><code>num_queries = (target_security_bits - query_pow_bits) / log_blowup
</code></pre>
<p>With default parameters (<code>target = 100 bits</code>, <code>query_pow_bits = 16</code>, <code>log_blowup = 3</code>):</p>
<pre><code>num_queries = (100 - 16) / 3 = 28
</code></pre>
<p>See related section in the <strong><a href="user_guide/./../advanced_topics/soundness.html">Soundness and Security</a></strong> chapter for a
more thorough analysis of the security estimate in the light of recent findings against the underlying
assumptions used in these heuristics.</p>
<h3 id="intermediate-layer-relaxation"><a class="header" href="#intermediate-layer-relaxation">Intermediate layer relaxation</a></h3>
<p>For intermediate recursive layers (not the final one), soundness requirements compose, so relaxed parameters can be used:</p>
<ul>
<li><code>query_pow_bits = 20</code>, <code>num_queries = 26</code> — saves 2 queries worth of in-circuit work</li>
<li><code>query_pow_bits = 24</code>, <code>num_queries = 25</code> — more aggressive, suitable for deeply nested layers</li>
</ul>
<p>The outermost (final) layer should use full-strength parameters.</p>
<h3 id="friverifierparams"><a class="header" href="#friverifierparams">FriVerifierParams</a></h3>
<p>The recursion circuit uses <code>FriVerifierParams</code> to know the FRI structure without accessing the native <code>FriParameters</code> directly:</p>
<pre><code class="language-rust ignore">let fri_verifier_params = FriVerifierParams::with_mmcs(
    log_blowup,
    log_final_poly_len,
    commit_pow_bits,
    query_pow_bits,
    poseidon2_config,
);</code></pre>
<p>This is stored in your config wrapper and returned via <code>FriRecursionConfig::pcs_verifier_params()</code>.</p>
<h2 id="poseidon2-configuration"><a class="header" href="#poseidon2-configuration">Poseidon2 configuration</a></h2>
<p>The <code>Poseidon2Config</code> enum selects the hash function parameters for in-circuit hashing (MMCS verification and Fiat-Shamir):</p>
<div class="table-wrapper"><table><thead><tr><th>Config</th><th>Field</th><th>D</th><th>WIDTH</th><th>RATE</th></tr></thead><tbody>
<tr><td><code>BabyBearD4Width16</code></td><td>BabyBear</td><td>4</td><td>16</td><td>8</td></tr>
<tr><td><code>BabyBearD1Width16</code></td><td>BabyBear</td><td>1</td><td>16</td><td>8</td></tr>
<tr><td><code>BabyBearD4Width24</code></td><td>BabyBear</td><td>4</td><td>24</td><td>12</td></tr>
<tr><td><code>KoalaBearD4Width16</code></td><td>KoalaBear</td><td>4</td><td>16</td><td>8</td></tr>
<tr><td><code>KoalaBearD1Width16</code></td><td>KoalaBear</td><td>1</td><td>16</td><td>8</td></tr>
<tr><td><code>KoalaBearD4Width24</code></td><td>KoalaBear</td><td>4</td><td>24</td><td>12</td></tr>
</tbody></table>
</div>
<p>For standard recursive verification, use the <code>D4Width16</code> variant matching your field. The <code>D1</code> variants use base field challenges (lower overhead per duplexing, but different security trade-offs). The <code>Width24</code> variants use a wider permutation for more efficient hashing.</p>
<p>The <code>Poseidon2Config</code> must be consistent between:</p>
<ul>
<li>The <code>FriRecursionBackend</code> constructor</li>
<li>The <code>FriVerifierParams</code></li>
<li>The Poseidon2 permutation enabled on the <code>CircuitBuilder</code></li>
</ul>
<h2 id="table-packing"><a class="header" href="#table-packing">Table packing</a></h2>
<p><code>TablePacking</code> controls how circuit operations are distributed across table lanes. Each lane adds columns to a table; more lanes means shorter (fewer rows) but wider (more columns) tables.</p>
<pre><code class="language-rust ignore">TablePacking::new(witness_lanes, public_lanes, alu_lanes)</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Controls</th><th>Trade-off</th></tr></thead><tbody>
<tr><td><code>witness_lanes</code></td><td>Witness table width</td><td>More lanes → fewer rows, but wider table</td></tr>
<tr><td><code>public_lanes</code></td><td>Public input table width</td><td>Often the bottleneck for row count</td></tr>
<tr><td><code>alu_lanes</code></td><td>ALU (add/mul) table width</td><td>Most operations land here</td></tr>
</tbody></table>
</div>
<p>The total row count of each table is <code>ceil(num_ops / num_lanes)</code>, padded to the next power of two. The <strong>maximum table height</strong> across all tables determines the FRI polynomial degree and dominates proving cost.</p>
<h3 id="choosing-packing-values"><a class="header" href="#choosing-packing-values">Choosing packing values</a></h3>
<p>The goal is to balance table heights so no single table forces a large power-of-two padding.</p>
<p><strong>Example</strong> — a recursive verification circuit with ~65K witness ops, ~43K public ops, ~60K ALU ops:</p>
<div class="table-wrapper"><table><thead><tr><th>Packing</th><th>Max height</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>(5, 1, 3)</code></td><td>2^16 = 65,536</td><td>Public table (43K/1 = 43K rows) forces 2^16</td></tr>
<tr><td><code>(5, 2, 3)</code></td><td>2^15 = 32,768</td><td>Public drops to 21.5K, halving the max</td></tr>
<tr><td><code>(5, 3, 3)</code></td><td>2^15 = 32,768</td><td>Public at 14.3K, ALU at 20K — both fit in 2^15</td></tr>
<tr><td><code>(8, 4, 4)</code></td><td>2^14 = 16,384</td><td>Everything fits, but tables are very wide</td></tr>
</tbody></table>
</div>
<p>Halving the max table height cuts FRI proving time by roughly 40-50% (one fewer folding round, half the polynomial size).</p>
<p>Use <code>.with_fri_params(log_final_poly_len, log_blowup)</code> to set minimum row counts:</p>
<pre><code class="language-rust ignore">let packing = TablePacking::new(5, 2, 3)
    .with_fri_params(log_final_poly_len, log_blowup);</code></pre>
<h3 id="layer-specific-packing"><a class="header" href="#layer-specific-packing">Layer-specific packing</a></h3>
<p>The first recursive layer (verifying the original proof) often has a different operation distribution than subsequent layers. It's common to use different packing per layer:</p>
<pre><code class="language-rust ignore">let packing = if layer == 1 {
    TablePacking::new(1, 1, 1)
} else {
    TablePacking::new(5, 1, 3)
}.with_fri_params(log_final_poly_len, log_blowup);</code></pre>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="public-inputs"><a class="header" href="#public-inputs">Public Inputs</a></h1>
<p>Public inputs are the values the verifier knows — they connect the circuit to the proof being verified. In recursive verification, the previous proof's commitments, opened values, and challenges become public inputs to the recursive circuit.</p>
<h2 id="how-public-inputs-flow"><a class="header" href="#how-public-inputs-flow">How public inputs flow</a></h2>
<p>When a verifier circuit is built, it allocates public input targets in a specific order. At proving time, concrete values must be packed in <strong>exactly the same order</strong>. If the order doesn't match, the proof will fail.</p>
<pre><code>Base proof (commitments, openings, challenges)
         │
         ▼
┌─────────────────────────┐
│   pack_public_inputs()  │  ← extracts values from the proof in allocation order
└─────────────────────────┘
         │
         ▼
   runner.set_public_inputs(&amp;packed_values)
</code></pre>
<h2 id="automatic-packing-via-the-unified-api"><a class="header" href="#automatic-packing-via-the-unified-api">Automatic packing via the unified API</a></h2>
<p>When using <code>prove_next_layer</code> or <code>build_and_prove_next_layer</code>, public input packing is handled automatically. The <code>VerifierCircuitResult::pack_public_inputs</code> method extracts values from the <code>RecursionInput</code> in the correct order.</p>
<p>You don't need to interact with the builders directly unless you're using the <a href="user_guide/./low_level_api.html">low-level API</a>.</p>
<h2 id="manual-packing-low-level-api"><a class="header" href="#manual-packing-low-level-api">Manual packing (low-level API)</a></h2>
<p>If building the verification circuit manually, use the dedicated builders:</p>
<h3 id="starkverifierinputsbuilder-uni-stark"><a class="header" href="#starkverifierinputsbuilder-uni-stark"><code>StarkVerifierInputsBuilder</code> (uni-STARK)</a></h3>
<p>Returned by <code>verify_p3_uni_proof_circuit</code>. Packs values from a <code>Proof&lt;SC&gt;</code>:</p>
<pre><code class="language-rust ignore">let public_inputs = verifier_inputs.pack_values(
    &amp;air_public_inputs,
    &amp;proof,
    &amp;preprocessed_commit,
);
runner.set_public_inputs(&amp;public_inputs)?;</code></pre>
<h3 id="batchstarkverifierinputsbuilder-batch-stark"><a class="header" href="#batchstarkverifierinputsbuilder-batch-stark"><code>BatchStarkVerifierInputsBuilder</code> (batch-STARK)</a></h3>
<p>Returned by <code>verify_p3_batch_proof_circuit</code>. Packs values from a <code>BatchProof&lt;SC&gt;</code> and <code>CommonData&lt;SC&gt;</code>:</p>
<pre><code class="language-rust ignore">let public_inputs = verifier_inputs.pack_values(
    &amp;table_public_inputs,
    &amp;batch_proof,
    &amp;common_data,
);
runner.set_public_inputs(&amp;public_inputs)?;</code></pre>
<h3 id="publicinputbuilder-generic"><a class="header" href="#publicinputbuilder-generic"><code>PublicInputBuilder</code> (generic)</a></h3>
<p>For custom circuits (not recursive verification), use the generic builder:</p>
<pre><code class="language-rust ignore">let mut builder = PublicInputBuilder::new();
builder
    .add_proof_values(proof_values)
    .add_challenge(alpha)
    .add_challenges(betas);
let public_inputs = builder.build();</code></pre>
<h2 id="public-inputs-in-aggregation"><a class="header" href="#public-inputs-in-aggregation">Public inputs in aggregation</a></h2>
<p>For aggregation circuits, public inputs from both verifications are concatenated — left first, then right. This is handled automatically by <code>prove_aggregation_layer</code>:</p>
<pre><code class="language-rust ignore">let mut public_inputs = left_result.pack_public_inputs(&amp;left)?;
public_inputs.extend(right_result.pack_public_inputs(&amp;right)?);</code></pre>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="integration-guide"><a class="header" href="#integration-guide">Integration Guide</a></h1>
<p>This section explains how to wire Plonky3-recursion into your own project.</p>
<h2 id="implementing-frirecursionconfig"><a class="header" href="#implementing-frirecursionconfig">Implementing <code>FriRecursionConfig</code></a></h2>
<p>The unified API requires your STARK config to implement <code>FriRecursionConfig</code>. This trait bridges your native Plonky3 config with the recursive verifier's type system.</p>
<p>The typical pattern is a wrapper struct that holds both the native config and the <code>FriVerifierParams</code>:</p>
<pre><code class="language-rust ignore">use p3_recursion::{
    FriRecursionConfig, FriVerifierParams, Poseidon2Config,
    RecursionInput, RecursiveAir, pcs::*,
};

#[derive(Clone)]
struct MyRecursionConfig {
    config: Arc&lt;MyStarkConfig&gt;,
    fri_verifier_params: FriVerifierParams,
}</code></pre>
<h3 id="delegate-starkgenericconfig"><a class="header" href="#delegate-starkgenericconfig">Delegate <code>StarkGenericConfig</code></a></h3>
<p>The wrapper must implement <code>StarkGenericConfig</code> by delegating to the inner config:</p>
<pre><code class="language-rust ignore">impl StarkGenericConfig for MyRecursionConfig {
    type Challenge = Challenge;
    type Challenger = Challenger;
    type Pcs = MyPcs;

    fn pcs(&amp;self) -&gt; &amp;MyPcs { self.config.pcs() }
    fn initialise_challenger(&amp;self) -&gt; Challenger { self.config.initialise_challenger() }
}</code></pre>
<h3 id="implement-frirecursionconfig"><a class="header" href="#implement-frirecursionconfig">Implement <code>FriRecursionConfig</code></a></h3>
<p>The trait requires five associated types and four methods:</p>
<pre><code class="language-rust ignore">impl FriRecursionConfig for MyRecursionConfig {
    type Commitment = MerkleCapTargets&lt;F, DIGEST_ELEMS&gt;;
    type InputProof = InputProofTargets&lt;F, Challenge, RecValMmcs&lt;F, DIGEST_ELEMS, MyHash, MyCompress&gt;&gt;;
    type OpeningProof = FriProofTargets&lt;...&gt;;
    type RawOpeningProof = &lt;MyPcs as Pcs&lt;Challenge, Challenger&gt;&gt;::Proof;
    const DIGEST_ELEMS: usize = 8;

    fn with_fri_opening_proof&lt;'a, A, R&gt;(
        prev: &amp;RecursionInput&lt;'a, Self, A&gt;,
        f: impl FnOnce(&amp;Self::RawOpeningProof) -&gt; R,
    ) -&gt; R {
        match prev {
            RecursionInput::UniStark { proof, .. } =&gt; f(&amp;proof.opening_proof),
            RecursionInput::BatchStark { proof, .. } =&gt; f(&amp;proof.proof.opening_proof),
        }
    }

    fn enable_poseidon2_on_circuit(
        &amp;self,
        circuit: &amp;mut CircuitBuilder&lt;Challenge&gt;,
    ) -&gt; Result&lt;(), VerificationError&gt; {
        let perm = default_poseidon2_perm();
        circuit.enable_poseidon2_perm::&lt;MyPoseidon2CircuitConfig, _&gt;(
            generate_poseidon2_trace::&lt;Challenge, MyPoseidon2CircuitConfig&gt;,
            perm,
        );
        Ok(())
    }

    fn pcs_verifier_params(&amp;self) -&gt; &amp;FriVerifierParams {
        &amp;self.fri_verifier_params
    }

    fn set_fri_private_data(
        runner: &amp;mut CircuitRunner&lt;Challenge&gt;,
        op_ids: &amp;[NonPrimitiveOpId],
        opening_proof: &amp;Self::RawOpeningProof,
    ) -&gt; Result&lt;(), &amp;'static str&gt; {
        set_fri_mmcs_private_data::&lt;F, Challenge, ChallengeMmcs, ValMmcs, MyHash, MyCompress, DIGEST_ELEMS&gt;(
            runner, op_ids, opening_proof,
        )
    }
}</code></pre>
<p>The concrete types (<code>MyHash</code>, <code>MyCompress</code>, <code>ValMmcs</code>, etc.) must match your native Plonky3 prover setup. See the examples for complete implementations.</p>
<h2 id="verifying-your-own-air"><a class="header" href="#verifying-your-own-air">Verifying your own AIR</a></h2>
<p>To recursively verify a proof produced by a custom AIR, implement <code>RecursiveAir</code> for your AIR type:</p>
<pre><code class="language-rust ignore">impl RecursiveAir&lt;F, EF, LogUpGadget&gt; for MyAir {
    fn width(&amp;self) -&gt; usize {
        // Number of main trace columns in your AIR
        MY_AIR_WIDTH
    }

    fn eval_folded_circuit(
        &amp;self,
        builder: &amp;mut CircuitBuilder&lt;EF&gt;,
        sels: &amp;RecursiveLagrangeSelectors,
        alpha: &amp;Target,
        lookup_metadata: &amp;LookupMetadata&lt;'_, F&gt;,
        columns: ColumnsTargets&lt;'_&gt;,
        lookup_gadget: &amp;LogUpGadget,
    ) -&gt; Target {
        // Convert your AIR's symbolic constraints to circuit form
        // and fold them with alpha.
        // Use `symbolic_to_circuit` or build manually.
    }

    fn get_log_num_quotient_chunks(
        &amp;self,
        preprocessed_width: usize,
        num_public_values: usize,
        contexts: &amp;[Lookup&lt;F&gt;],
        lookup_data: &amp;[LookupData&lt;usize&gt;],
        is_zk: usize,
        lookup_gadget: &amp;LogUpGadget,
    ) -&gt; usize {
        // log2 of the number of quotient polynomial chunks.
        // Must match what the native prover uses.
    }
}</code></pre>
<p>For AIRs built with Plonky3's <code>Air</code> trait, the symbolic constraint extraction and folding can be done generically using <code>get_symbolic_constraints</code> and <code>symbolic_to_circuit</code>, as described in <a href="user_guide/./circuit_building.html#building-recursive-air-constraints">Circuit Building</a>.</p>
<p>Then wrap your proof in <code>RecursionInput::UniStark</code>:</p>
<pre><code class="language-rust ignore">let input = RecursionInput::UniStark {
    proof: &amp;my_proof,
    air: &amp;my_air,
    public_inputs: my_public_values.clone(),
    preprocessed_commit: Some(preprocessed_commitment),  // if your AIR has preprocessed columns
};</code></pre>
<h2 id="custom-non-primitive-chips"><a class="header" href="#custom-non-primitive-chips">Custom non-primitive chips</a></h2>
<p>The circuit builder supports registering custom non-primitive operations beyond Poseidon2. These are operations that are too expensive to express purely in primitives and benefit from dedicated AIR tables.</p>
<p>Non-primitive operations:</p>
<ul>
<li>Are controlled by a runtime policy (<code>DefaultProfile</code> disables all, <code>AllowAllProfile</code> enables all)</li>
<li>Require a custom trace builder for trace generation</li>
<li>Interact with the witness table via lookups, and may additionally use private data</li>
</ul>
<p>To enable a non-primitive operation, call the appropriate <code>enable_*</code> method on the <code>CircuitBuilder</code> before building. Attempting to use a non-primitive operation that hasn't been enabled will result in a runtime error.</p>
<h2 id="end-to-end-integration-checklist"><a class="header" href="#end-to-end-integration-checklist">End-to-end integration checklist</a></h2>
<ol>
<li>Set up your Plonky3 prover config (field, hash, PCS, FRI params)</li>
<li>Create a config wrapper implementing <code>FriRecursionConfig</code></li>
<li>If verifying a custom AIR: implement <code>RecursiveAir</code></li>
<li>Create a <code>FriRecursionBackend</code> with matching <code>Poseidon2Config</code></li>
<li>Choose <code>TablePacking</code> values (start with defaults, tune later)</li>
<li>Call <code>build_and_prove_next_layer</code> or the split build/prove variant</li>
<li>Chain layers with <code>into_recursion_input::&lt;BatchOnly&gt;()</code></li>
<li>Verify the final proof with <code>BatchStarkProver::verify_all_tables</code></li>
</ol>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="low-level-api"><a class="header" href="#low-level-api">Low-Level API</a></h1>
<p>For fine-grained control over the verification circuit, you can bypass the unified API and build the pipeline manually.</p>
<h2 id="manual-uni-stark-verification"><a class="header" href="#manual-uni-stark-verification">Manual uni-STARK verification</a></h2>
<pre><code class="language-rust ignore">use p3_recursion::verifier::verify_p3_uni_proof_circuit;
use p3_recursion::public_inputs::StarkVerifierInputsBuilder;
use p3_circuit::CircuitBuilder;

let mut circuit_builder = CircuitBuilder::new();

// Enable Poseidon2 for MMCS verification
circuit_builder.enable_poseidon2_perm::&lt;MyPoseidon2Config, _&gt;(trace_generator, perm);

// Allocate public input targets and build verification constraints
let verifier_inputs = StarkVerifierInputsBuilder::allocate(
    &amp;mut circuit_builder, &amp;proof, preprocessed_commit.as_ref(), num_public_values,
);

let op_ids = verify_p3_uni_proof_circuit::&lt;
    MyAir, MyConfig, CommitTargets, InputProofTargets, OpeningProofTargets,
    WIDTH, RATE,
&gt;(
    &amp;config, &amp;air, &amp;mut circuit_builder,
    &amp;verifier_inputs.proof_targets,
    &amp;verifier_inputs.air_public_targets,
    &amp;verifier_inputs.preprocessed_commit,
    &amp;fri_verifier_params,
    poseidon2_config,
)?;

// Build and run
let circuit = circuit_builder.build()?;
let mut runner = circuit.runner();

let public_inputs = verifier_inputs.pack_values(&amp;pis, &amp;proof, &amp;preprocessed_commit);
runner.set_public_inputs(&amp;public_inputs)?;

set_fri_mmcs_private_data(&amp;mut runner, &amp;op_ids, &amp;proof.opening_proof)?;

let traces = runner.run()?;</code></pre>
<h2 id="manual-batch-stark-verification"><a class="header" href="#manual-batch-stark-verification">Manual batch-STARK verification</a></h2>
<pre><code class="language-rust ignore">use p3_recursion::verifier::verify_p3_batch_proof_circuit;

let mut circuit_builder = CircuitBuilder::new();
circuit_builder.enable_poseidon2_perm::&lt;MyPoseidon2Config, _&gt;(trace_generator, perm);

let lookup_gadget = LogUpGadget::new();

let (verifier_inputs, op_ids) = verify_p3_batch_proof_circuit::&lt;
    MyConfig, CommitTargets, InputProofTargets, OpeningProofTargets, LogUpGadget,
    WIDTH, RATE, TRACE_D,
&gt;(
    &amp;config, &amp;mut circuit_builder, &amp;batch_proof,
    &amp;fri_verifier_params, &amp;common_data, &amp;lookup_gadget, poseidon2_config,
)?;

let circuit = circuit_builder.build()?;
let mut runner = circuit.runner();

let public_inputs = verifier_inputs.pack_values(
    &amp;table_public_inputs, &amp;batch_proof.proof, &amp;common_data,
);
runner.set_public_inputs(&amp;public_inputs)?;

set_fri_mmcs_private_data(&amp;mut runner, &amp;op_ids, &amp;batch_proof.proof.opening_proof)?;

let traces = runner.run()?;</code></pre>
<h2 id="proving-the-verification-circuit"><a class="header" href="#proving-the-verification-circuit">Proving the verification circuit</a></h2>
<p>Once you have traces, prove them with <code>BatchStarkProver</code>:</p>
<pre><code class="language-rust ignore">use p3_circuit_prover::{BatchStarkProver, CircuitProverData};
use p3_circuit_prover::common::get_airs_and_degrees_with_prep;

let (airs_degrees, preprocessed) = get_airs_and_degrees_with_prep::&lt;SC, EF, D&gt;(
    &amp;circuit, table_packing, Some(&amp;[NonPrimitiveConfig::Poseidon2(poseidon2_config)]),
)?;

let (mut airs, degrees): (Vec&lt;_&gt;, Vec&lt;_&gt;) = airs_degrees.into_iter().unzip();
let prover_data = ProverData::from_airs_and_degrees(&amp;config, &amp;mut airs, &amp;degrees);
let circuit_prover_data = CircuitProverData::new(prover_data, preprocessed);

let mut prover = BatchStarkProver::new(config.clone())
    .with_table_packing(table_packing);
prover.register_poseidon2_table(poseidon2_config);

let proof = prover.prove_all_tables(&amp;traces, &amp;circuit_prover_data)?;</code></pre>
<h2 id="when-to-use-the-low-level-api"><a class="header" href="#when-to-use-the-low-level-api">When to use the low-level API</a></h2>
<ul>
<li>You need to inspect or modify the circuit between building and proving</li>
<li>You want to share a single <code>CircuitBuilder</code> across multiple verification circuits (custom aggregation patterns beyond 2-to-1)</li>
<li>You need to inject additional constraints into the verification circuit</li>
<li>You want to separate circuit construction from execution for caching or serialization</li>
</ul>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="recursion-approach-and-construction"><a class="header" href="#recursion-approach-and-construction">Recursion Approach and Construction</a></h1>
<h2 id="high-level-architecture"><a class="header" href="#high-level-architecture">High-level architecture</a></h2>
<p>Recursion in zero-knowledge proofs means using one proof to verify another: an (outer) prover will generate a proof
to assert validity of an (inner) STARK proof. By applying this recursively, one obtains a (possibly compact) outer proof that attests to arbitrarily deep chains of computation.</p>
<p>Our approach to recursion for Plonky3 differs from a traditional zkVM approach: there is <strong>no program counter, instruction set, or branching logic</strong>. Instead, a fixed program is chosen, and the verifier circuit is specialized to this program only.</p>
<h2 id="why-fixing-the-program-shape"><a class="header" href="#why-fixing-the-program-shape">Why fixing the program shape?</a></h2>
<ul>
<li>
<p><strong>Performance</strong>: without program counter logic, branching, or instruction decoding,
the verifier’s constraints are much lighter.</p>
</li>
<li>
<p><strong>Recursion efficiency</strong>: since the shape of the trace is predetermined,
the recursion circuit can be aggressively optimized.</p>
</li>
<li>
<p><strong>Simplicity</strong>: all inputs follow the same structural pattern, which keeps
implementation complexity low.</p>
</li>
</ul>
<p>By fixing the program to execute, in particular here proving the correct verification of some <em>known</em> AIR(s) program(s), prover and verifier can agree on the integral execution flow of the program.
As such, each step corresponds to an instruction <strong>known at compile-time</strong> with operands either known at compile-time in the case of constants, or defined by the prover at runtime. This removes all the
overhead of handling arbitrary control flow, and makes the resulting AIR(s) statement(s) effectively tailored for the program they represent, as opposed to regular VMs.</p>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<ul>
<li>
<p><strong>Rigidity</strong>: only the supported program(s) can be proven.</p>
</li>
<li>
<p><strong>No variable-length traces</strong>: input size must fit the circuit’s predefined structure.</p>
</li>
<li>
<p><strong>Reusability</strong>: adapting to a new program requires a new circuit.</p>
</li>
</ul>
<p>The rest of this book explains how this approach is built, <a href="architecture_and_internals/scaling.html">how to soften its rigidity</a>,
and why it provides a powerful foundation for recursive proof systems.</p>
<h2 id="execution-ir"><a class="header" href="#execution-ir">Execution IR</a></h2>
<p>An <strong>Execution IR</strong> (intermediate representation) is defined to describe the steps of the verifier.
This IR is <em>not itself proved</em>, but will be used as source of truth between prover and verifier to guide trace population.
The actual soundness comes from the constraints inside the operation-specific STARK chips along with an aggregated lookup argument ensuring consistency of the common values they operate on.
The lookups can be seen as representing the <code>READ</code>/<code>WRITE</code> operations from/to the witness table.</p>
<p>The example below represents the (fixed) IR associated to the statement <code>37.x - 111 = 0</code>, where <code>x</code> is a public input. It can be reproduced by running</p>
<pre><code class="language-bash">RUST_LOG=debug cargo test --package p3-circuit --lib -- tables::runner::tests::test_toy_example_37_times_x_minus_111 --exact --show-output
</code></pre>
<p>A given row of the represented IR contains an operation and its associated operands.</p>
<pre><code class="language-bash">=== CIRCUIT PRIMITIVE OPERATIONS ===
0: Const { out: WitnessId(0), val: 0 }
1: Const { out: WitnessId(1), val: 37 }
2: Const { out: WitnessId(2), val: 111 }
3: Public { out: WitnessId(3), public_pos: 0 }
4: Alu { a: WitnessId(1), b: WitnessId(3), out: WitnessId(4), mul_selector: 1 }
5: Alu { a: WitnessId(2), b: WitnessId(0), out: WitnessId(4), add_selector: 1 }
</code></pre>
<p>i.e. operation 4 performs <code>w[4] &lt;- w[1] * w[3]</code>, and operation 5 encodes the subtraction check as an addition <code>w[2] + w[0] = w[4]</code> (verifying <code>37 * x - 111 = 0</code>).</p>
<p>In order to generate the IR, the first step is to create all operations symbolically.</p>
<p>In the symbolic executor, the computation is represented as a graph where nodes are called either <code>ExprId</code> (since they represent the index of an expression) or <code>Target</code> in the code. Each <code>Target</code> can be:</p>
<ul>
<li>a constant,</li>
<li>a public input,</li>
<li>the output of an operation.</li>
</ul>
<p>The computation graph that represents all operations in the IR is called <code>Circuit</code>.</p>
<p>A <code>circuit_builder</code> provides convenient helper functions and macros for representing and defining operations within this graph. See section <a href="architecture_and_internals/./circuit_building.html#building-circuits">Building Circuits</a> for more details on how to build a circuit.</p>
<h2 id="witness-table"><a class="header" href="#witness-table">Witness Table</a></h2>
<p>The <code>Witness</code> table can be seen as a central memory bus that stores values shared across all operations. It is represented as pairs <code>(index, value)</code>, where indices are  that will be accessed by
the different chips via lookups to enforce consistency.</p>
<ul>
<li>The index column is <em>preprocessed</em>, or <em>read-after-preprocess</em> (<a href="https://hackmd.io/@aztec-network/plonk-arithmetiization-air">RAP</a>): it is known to both prover and verifier in advance, requiring no online commitment.<sup class="footnote-reference" id="fr-1-1"><a href="#footnote-1">1</a></sup></li>
<li>The <code>Witness</code> table values are represented as extension field elements directly (where base field elements are padded with 0 on higher coordinates) for addressing efficiency.</li>
</ul>
<p>From the fixed IR of the example above, we can deduce an associated <code>Witness</code> table as follows:</p>
<pre><code class="language-bash">=== WITNESS TRACE ===
Row 0: WitnessId(w0) = 0
Row 1: WitnessId(w1) = 37
Row 2: WitnessId(w2) = 111
Row 3: WitnessId(w3) = 3
Row 4: WitnessId(w4) = 111
</code></pre>
<p>Note that the initial version of the recursion machine, for the sake of simplicity and ease of iteration, contains a <code>Witness</code> table. However, because the verifier effectively knows the order of
each operation and the interaction between them, the <code>Witness</code> table can be entirely removed, and global consistency can still be enforced at the cost of additional (smaller) lookups between the different chips.</p>
<h2 id="operation-specific-stark-chips"><a class="header" href="#operation-specific-stark-chips">Operation-specific STARK Chips</a></h2>
<p>Each operation family (e.g. addition, multiplication, MMCS path verification, FRI folding) has its own chip.</p>
<p>A chip contains:</p>
<ul>
<li>Local columns for its variables.</li>
<li>Lookup ports into the <code>Witness</code> table.</li>
<li>An AIR that enforces its semantics.</li>
</ul>
<p>We distinguish two kind of chips: those representing native, i.e. primitive operations, and additional non-primitive ones, defined at runtime, that serve as precompiles to optimize certain operations.
The recursion machine contains 3 primitive chips: <code>CONST</code>, <code>PUBLIC_INPUT</code>, and a unified <code>ALU</code> chip with three selector columns (add/mul, bool-check, mul-add). <code>SUB</code> and <code>DIV</code> are encoded as ALU rows using the add or mul operation.</p>
<p>Given only the primitive operations, one should be able to carry out most operations necessary in circuit verification. Primitive operations have the following properties:</p>
<ul>
<li>They operate on elements of the <code>Witness</code> table, through their <code>WitnessId</code> (index within the <code>Witness</code> table).</li>
<li>The representation can be heavily optimized. For example, every time a constant is added to the IR, we either create a new <code>WitnessId</code> or return an already existing one. We could also carry out common subexpression elimination.</li>
<li>They are executed in topological order during the circuit evaluation, and they form a directed acyclic graph of dependencies.</li>
</ul>
<p>But relying only on primitive operations for the entire verification would lead to the introduction of many temporary values in the IR. In turn, this would lead to enlarged <code>Witness</code> and primitive tables. To reduce the overall surface area of our AIRs, we can introduce <em>non-primitive</em> specialized chips that carry out specific (non-primitive) operations. We can offload repeated computations to these non-primitive chips to optimize the overall proving flow.</p>
<p>These non-primitive operations use not only <code>Witness</code> table elements (including public inputs), but may also require the use of <em>private data</em>. For example, when verifying a Merkle path, hash outputs are not stored in the <code>Witness</code> table.</p>
<p>This library aims at providing a certain
number of non-primary chips so that projects can natively inherit from full recursive verifiers, which implies chips for FRI, MMCS path verification, etc. Specific applications can also build their own
non-primitive chips and plug them at runtime.</p>
<p>Going back to the previous example, prover and verifier can agree on the following logic for each chip:</p>
<pre><code class="language-bash">=== CONST TRACE ===
Row 0: WitnessId(w0) = 0
Row 1: WitnessId(w1) = 37
Row 2: WitnessId(w2) = 111

=== PUBLIC TRACE ===
Row 0: WitnessId(w3) = 3

=== ALU TRACE ===
Row 0: mul: WitnessId(w1) * WitnessId(w3) -&gt; WitnessId(w4) | 37 * 3 -&gt; 111
Row 1: add: WitnessId(w2) + WitnessId(w0) -&gt; WitnessId(w4) | 111 + 0 -&gt; 111
</code></pre>
<p>Note that because we started from a known, fixed program that has been lowered to a deterministic IR, we can have the <code>CONST</code> chip's table entirely preprocessed
(i.e. known to the verifier), as well as all <code>index</code> columns of the other primitive chips.</p>
<h2 id="lookups"><a class="header" href="#lookups">Lookups</a></h2>
<p>All chips interactions are performed via a lookup argument. Enforcing multiset equality between all chip ports and the <code>Witness</code> table entries ensures correctness without proving the execution order of the entire IR itself. Lookups can be seen as <code>READ</code>/<code>WRITE</code> or <code>RECEIVE</code>/<code>SEND</code> interactions between tables which allow global consistency over local AIRs.</p>
<p>Cross-table lookups (CTLs) ensure that <strong>every</strong> chip interaction happens through the Witness table: producers write a <code>(index, value)</code> pair into Witness and consumers read the same pair back. No chip talks directly to any other chip; the aggregated LogUp argument enforces multiset equality between the writes and reads.</p>
<p>For the toy example the CTL relations are:<sup class="footnote-reference" id="fr-2-1"><a href="#footnote-2">2</a></sup></p>
<pre><code class="language-bash">(index 0, value 0)   : CONST → Witness → ALU(add row)
(index 1, value 37)  : CONST → Witness → ALU(mul row)
(index 2, value 111) : CONST → Witness → ALU(add row)
(index 3, value 3)   : PUBLIC → Witness → ALU(mul row)
(index 4, value 111) : ALU(mul row) → Witness ← ALU(add row)
</code></pre>
<hr>
<ol class="footnote-definition"><li id="footnote-1">
<p>Preprocessed columns / polynomials can be reconstructed manually by the verifier, removing the need for a prover to commit to them and later perform the FRI protocol on them. However, the verifier needs <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> work when these columns are not structured, as it still needs to interpolate them. To alleviate this, the Plonky3 recursion stack performs <em>offline</em> commitment of unstructured preprocessed columns, so that we need only one instance of the FRI protocol to verify all preprocessed columns evaluations. <a href="#fr-1-1">↩</a></p>
</li>
<li id="footnote-2">
<p>The two ALU rows both write <code>w4 = 111</code> to the Witness table (once via a mul row, once via an add row). Because the Witness table is a <em>read-only</em> / <em>write-once</em> memory bus, the aggregated lookup forces those duplicate writes to agree, which is exactly the constraint <code>37 * 3 = 111 = 0 + 111</code>. <a href="#fr-2-1">↩</a></p>
</li>
</ol><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="building-circuits"><a class="header" href="#building-circuits">Building Circuits</a></h1>
<p>This section explains how the <code>CircuitBuilder</code> allows to build a concrete <code>Circuit</code> for a given program.
We’ll use a simple Fibonacci example throughout this page to ground the ideas behind circuit building:</p>
<pre><code class="language-rust ignore">let mut builder = CircuitBuilder::&lt;F&gt;::new();

// Public input: expected F(n)
let expected_result = builder.public_input();

// Compute F(n) iteratively
let mut a = builder.define_const(F::ZERO); // F(0)
let mut b = builder.define_const(F::ONE);  // F(1)

for _i in 2..=n {
    let next = builder.add(a, b); // F(N) &lt;- F(N-1) + F(N-2)
    a = b;
    b = next;
}

// Assert computed F(n) equals expected result
builder.connect(b, expected_result);

let circuit = builder.build()?;
let mut runner = circuit.runner();</code></pre>
<h2 id="building-pipeline"><a class="header" href="#building-pipeline">Building Pipeline</a></h2>
<p>In what follows, we call <code>WitnessId</code> what serves as identifier for values in the global Witness storage bus, and
<code>ExprId</code> position identifiers in the <code>ExpressionGraph</code> (with the hardcoded constant <code>ZERO</code> always stored at position 0).</p>
<p>Building a circuit works in 4 successive steps:</p>
<h3 id="stage-1--lower-to-primitives"><a class="header" href="#stage-1--lower-to-primitives">Stage 1 — Lower to primitives</a></h3>
<p>This stage will go through the <code>ExpressionGraph</code> in successive passes and emit primitive operations.</p>
<ul>
<li>
<p>when going through emitted <code>Const</code> nodes, the builder ensures no identical constants appear in distinct nodes of the circuit, seen as a DAG (Directed Acyclic Graph), by performing witness aliasing, i.e. looking at node equivalence classes. This allows to prune duplicated <code>Const</code> nodes by replacing further references with the single equivalence class representative that will be part of the DAG. This allows to enforce equality constraints are <strong>structurally</strong>, without requiring extra gates.</p>
</li>
<li>
<p>public inputs and arithmetic operations may also reuse pre-allocated slots if connected to some existing node.</p>
</li>
</ul>
<h3 id="stage-2--lower-non-primitives"><a class="header" href="#stage-2--lower-non-primitives">Stage 2 — Lower non-primitives</a></h3>
<p>This stage translates the <code>ExprId</code> of logged non-primitive operations inputs (from the set of non-primitive operations allowed at runtime) to <code>WitnessId</code>s similarly to Stage 1.</p>
<h3 id="stage-3--optimize-primitives"><a class="header" href="#stage-3--optimize-primitives">Stage 3 — Optimize primitives</a></h3>
<p>This stage aims at optimizing the generated circuit by removing or optimizing redundant operations within the graph.
For instance, if the output of a primitive operation is never used elsewhere in the circuit, its associated node can
be pruned away from the graph, and the operation removed.</p>
<p>Once all the nodes have been assigned, and the circuit has been fully optimized, we output it.</p>
<h2 id="building-recursive-air-constraints"><a class="header" href="#building-recursive-air-constraints">Building recursive AIR constraints</a></h2>
<p>In order to recursively verify an AIR, its constraints need to be added to the circuit and folded together. In Plonky3, we can get an AIR's constraints in symbolic form. Since our primitive chips (see section <a href="architecture_and_internals/./construction.html#execution-ir">Execution IR</a>) encompass the various entries in the symbolic representation, we can simply map each symbolic operation to its circuit counterpart. The <code>symbolic_to_circuit</code> function does exactly that for a given symbolic constraint.</p>
<p>We can consider a small example to show how operations are mapped. Given public inputs <code>a</code> and <code>b</code>, and a constant <code>c</code>, we have the following symbolic constraint: <code>Mul{ a, Sub {b, Const{ c }}}</code> (which corresponds to: <code>a * (b - c)</code>).</p>
<pre><code class="language-rust ignore">// We get the `ExprId` corresponding to Const{ c } by adding a constant to the circuit.
let x = builder.define_const(c);
// We use the previously computed `x` to compute the subtraction in the circuit.
let y = builder.sub(b, x);
// We use the previously computed `y` to compute the multiplication in the circuit.
let z = builder.mul(a, y);</code></pre>
<p><code>z</code> is then the output <code>ExprId</code> of the constraint in the circuit.</p>
<p>Using this function, we have implemented, for all AIRs, the automatic translation from their set of symbolic constraints to the circuit version of the folded constraints:</p>
<pre><code class="language-rust ignore">// Transforms an AIR's symbolic constraints into its counterpart circuit version, 
// and folds all the constraints in the circuit using the challenge `alpha`.
fn eval_folded_circuit(
        // The AIR at hand.
        &amp;self,
        builder: &amp;mut CircuitBuilder&lt;F&gt;,
        // Circuit version of Langrange selectors.
        sels: &amp;RecursiveLagrangeSelectors,
        // Folding challenge.
        alpha: &amp;ExprId,
        // All kind of columns that could be involved in constraints.
        columns: ColumnsTargets,
    ) -&gt; Target {
        // Get all the constraints in symbolic form.
        let symbolic_constraints = 
            get_symbolic_constraints(self, 0, columns.public_values.len());

        // Fold all the constraints using the folding challenge.
        let mut acc = builder.define_const(F::ZERO);
        for s_c in symbolic_constraints {
            let mul_prev = builder.mul(acc, *alpha);

            // Get the current constraint in circuit form.
            let constraints = 
                symbolic_to_circuit(sels.row_selectors, &amp;columns, &amp;s_c, builder);

            // Fold the current constraint with the previous value.
            acc = builder.add(mul_prev, constraints);
        }

        acc
    }</code></pre>
<p>This facilitates the integration of <em>any</em> AIR verification into our circuit.</p>
<h2 id="proving"><a class="header" href="#proving">Proving</a></h2>
<p>Calling <code>circuit.runner()</code> will return a instance of <code>CircuitRunner</code> allowing to execute the
represented program and generate associated execution traces needed for proving:</p>
<pre><code class="language-rust ignore">let mut runner = circuit.runner();

// Set public input
let expected_fib = compute_fibonacci_classical(n);
runner.set_public_inputs(&amp;[expected_fib])?;

// Instantiate prover instance
let config = build_standard_config_koalabear();
let prover = BatchStarkProver::new(config);

// Generate traces
let traces = runner.run()?;

// Prove the program
let proof = prover.prove_all_tables(&amp;traces)?;</code></pre>
<h2 id="key-takeaways"><a class="header" href="#key-takeaways">Key takeaways</a></h2>
<ul>
<li>
<p><strong>“Free” equality constraints:</strong> by leveraging <strong>witness aliasing</strong>, we obtain essentially free equality constraints for the prover, removing the need for additional arithmetic constraints.</p>
</li>
<li>
<p><strong>Deterministic layout:</strong> The ordered primitive lowering combined with equivalence class allocation yields predictable <code>WitnessId</code>s.</p>
</li>
<li>
<p><strong>Minimal primitive set:</strong> With <code>Sub</code>/<code>Div</code> being effectively translated as equivalent <code>Add</code>/<code>Mul</code> operations, the IR stays extremely lean, consisting only of <code>Const</code>, <code>Public</code>, <code>Add</code> and <code>Mul</code>, simplifying the design and implementation details.</p>
</li>
</ul>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="hashing-and-fiat-shamir-in-recursion"><a class="header" href="#hashing-and-fiat-shamir-in-recursion">Hashing and Fiat-Shamir in Recursion</a></h1>
<p>This section explains how cryptographic hashing, specifically Poseidon2, is used in recursive verification,
and how the Fiat-Shamir challenger is implemented to maintain transcript compatibility with native Plonky3.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Recursive verification requires two distinct uses of the permutation used by the selected prover configuration:</p>
<ol>
<li><strong>Fiat-Shamir Challenger</strong>: Derives random challenges from the transcript (commitments, opened values, etc.)</li>
<li><strong>MMCS/Merkle Verification</strong>: Verifies Merkle tree opening proofs for commitments</li>
</ol>
<p>Both operations use the same underlying Poseidon2 permutation, but they interact with it differently:</p>
<pre><code>┌─────────────────────────────────────────────────────────────────────┐
│                    Poseidon2 Permutation (WIDTH=16)                 │
├──────────────────────────────┬──────────────────────────────────────┤
│     Fiat-Shamir Challenger   │        MMCS/Merkle Hashing           │
├──────────────────────────────┼──────────────────────────────────────┤
│ • Duplex sponge construction │ • Compression function               │
│ • Absorb/squeeze pattern     │ • Hash two siblings → parent         │
│ • ~20 calls per verification │ • Hundreds of calls per verification │
│ • Transcript-sensitive       │ • Position-sensitive                 │
└──────────────────────────────┴──────────────────────────────────────┘
</code></pre>
<h2 id="the-poseidon2-permutation"><a class="header" href="#the-poseidon2-permutation">The Poseidon2 Permutation</a></h2>
<p>In this implementation, we use the Poseidon2 permutation with:</p>
<ul>
<li><strong>WIDTH = 16</strong>: The permutation operates on 16 field elements</li>
<li><strong>RATE = 8</strong>: In sponge mode, 8 elements are absorbed/squeezed per permutation</li>
</ul>
<p><strong>Note</strong>: These parameters (WIDTH=16, RATE=8) are currently fixed and tailored to 32-bit fields.
Future versions will make them configurable to support a wider range of applications.</p>
<h3 id="base-field-vs-extension-field-views"><a class="header" href="#base-field-vs-extension-field-views">Base Field vs Extension Field Views</a></h3>
<p>The same Poseidon2 permutation can be viewed in two equivalent ways:</p>
<p><strong>D=1 View (Base Field)</strong></p>
<pre><code>Input:  [e₀, e₁, e₂, ..., e₁₅]     ← 16 base field elements
Output: [f₀, f₁, f₂, ..., f₁₅]     ← 16 base field elements
</code></pre>
<p><strong>D=4 View (Extension Field)</strong></p>
<pre><code>Input:  [E₀, E₁, E₂, E₃]           ← 4 extension field elements
Output: [F₀, F₁, F₂, F₃]           ← 4 extension field elements

where each Eᵢ = eᵢ₀ + eᵢ₁·ω + eᵢ₂·ω² + eᵢ₃·ω³
</code></pre>
<p>Both views represent the same Poseidon2 permutation over the base field. The difference is purely representational:</p>
<ul>
<li>D=1: Direct representation as 16 base field elements</li>
<li>D=4: Packed representation as 4 degree-4 extension field elements</li>
</ul>
<h2 id="the-fiat-shamir-challenger"><a class="header" href="#the-fiat-shamir-challenger">The Fiat-Shamir Challenger</a></h2>
<h3 id="native-plonky3-behavior"><a class="header" href="#native-plonky3-behavior">Native Plonky3 Behavior</a></h3>
<p>Plonky3's native <code>DuplexChallenger</code> maintains internal state as <strong>base field elements</strong>:</p>
<pre><pre class="playground"><code class="language-rust edition2024"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct DuplexChallenger&lt;F, Permutation, const WIDTH: usize, const RATE: usize&gt; {
    sponge_state: [F; WIDTH],        // 16 base field elements
    input_buffer: Vec&lt;F&gt;,            // Pending observations (0..RATE)
    output_buffer: Vec&lt;F&gt;,           // Available samples (0..RATE)
}
<span class="boring">}</span></code></pre></pre>
<p>The challenger implements a duplex sponge construction as follows:</p>
<pre><code>┌────────────────────────────────────────────────────────────────┐
│                     Duplex Sponge Operation                    │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│   observe(value):                                              │
│     1. Clear output_buffer (any pending outputs are invalid)   │
│     2. Push value to input_buffer                              │
│     3. If input_buffer.len() == RATE, apply duplexing:         │
│        • Overwrite state[0..RATE] with input_buffer            │
│        • Apply Poseidon2 permutation                           │
│        • Fill output_buffer from state[0..RATE]                │
│        • Clear input_buffer                                    │
│                                                                │
│   sample():                                                    │
│     1. If input_buffer not empty OR output_buffer empty:       │
│        • Trigger duplexing (same as step 3 above)              │
│     2. Pop and return from output_buffer                       │
│                                                                │
└────────────────────────────────────────────────────────────────┘
</code></pre>
<h3 id="circuit-challenger-design"><a class="header" href="#circuit-challenger-design">Circuit Challenger Design</a></h3>
<p>The recursive circuit operates over extension field elements, but must produce <strong>identical transcripts</strong> to the native challenger. This requires careful state management.</p>
<p>The <code>CircuitChallenger</code> maintains state as <strong>coefficient-level targets</strong>:</p>
<pre><pre class="playground"><code class="language-rust edition2024"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct CircuitChallenger&lt;const WIDTH: usize, const RATE: usize&gt; {
    state: Vec&lt;Target&gt;,           // Targets, (base field coefficients)
    input_buffer: Vec&lt;Target&gt;,    // Pending observations
    output_buffer: Vec&lt;Target&gt;,   // Available samples
    poseidon2_config: Poseidon2Config,
}
<span class="boring">}</span></code></pre></pre>
<p>Each target in <code>state</code> represents a base field element embedded in the extension field (i.e., only the constant coefficient is non-zero).</p>
<h3 id="duplexing-in-the-circuit"><a class="header" href="#duplexing-in-the-circuit">Duplexing in the Circuit</a></h3>
<p>When the circuit challenger needs to permute, it must bridge between coefficient-level state and the Poseidon2 permutation:</p>
<pre><code>    16 coefficient targets                4 extension targets
    [c₀, c₁, c₂, ..., c₁₅]    ────►     [E₀, E₁, E₂, E₃]
                               recompose
                                  │
                                  ▼
                          ┌─────────────┐
                          │  Poseidon2  │
                          │ Permutation │
                          └─────────────┘
                                  │
                                  ▼
    [c'₀, c'₁, c'₂, ..., c'₁₅]  ◄────   [F₀, F₁, F₂, F₃]
                               decompose
</code></pre>
<p><strong>Recomposition</strong> (16 coefficients → 4 extension elements):</p>
<pre><code>E₀ = c₀ + c₁·ω + c₂·ω² + c₃·ω³
E₁ = c₄ + c₅·ω + c₆·ω² + c₇·ω³
E₂ = c₈ + c₉·ω + c₁₀·ω² + c₁₁·ω³
E₃ = c₁₂ + c₁₃·ω + c₁₄·ω² + c₁₅·ω³
</code></pre>
<p><strong>Decomposition</strong> (4 extension elements → 16 coefficients):
The inverse operation, extracting basis coefficients from each extension element.</p>
<h3 id="row-overhead"><a class="header" href="#row-overhead">Row Overhead</a></h3>
<p>The recomposition/decomposition unfortunately adds overhead in the primitive tables:</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Mul Rows</th><th>Add Rows</th><th>Witness Rows</th></tr></thead><tbody>
<tr><td>Recompose (4 ext)</td><td>16</td><td>12</td><td>0</td></tr>
<tr><td>Decompose (4 ext)</td><td>16</td><td>12</td><td>16</td></tr>
<tr><td><strong>Total per duplexing</strong></td><td><strong>32</strong></td><td><strong>24</strong></td><td><strong>16</strong></td></tr>
</tbody></table>
</div>
<p>This adds a total of approximately <strong>70</strong> rows over the different primitive tables per challenger duplexing.</p>
<blockquote>
<p><strong>Optimization Note</strong>: When using D=1 configuration (base field challenges), no recomposition/decomposition
is needed as the state maps directly to the Poseidon2 inputs, eliminating this overhead.</p>
</blockquote>
<h2 id="coexistence-on-a-single-trace"><a class="header" href="#coexistence-on-a-single-trace">Coexistence on a Single Trace</a></h2>
<p>Both D=1 and D=4 views share the <strong>same Poseidon2 AIR trace</strong>.
The AIR constrains the Poseidon2 permutation over the base field regardless of how inputs/outputs are packed:</p>
<pre><code>┌───────────────────────────────────────────────────────────────────────────────────┐
│                          Poseidon2 AIR Trace (WIDTH=16)                           │
├───────────────────────────────────────────────────────────────────────────────────┤
│                                                                                   │
│  Each row: [s₀, s₁, s₂, s₃, s₄, s₅, s₆, s₇, s₈, s₉, s₁₀, s₁₁, s₁₂, s₁₃, s₁₄, s₁₅] │
│                                                                                   │
│  The AIR constraints enforce the Poseidon2 round function:                        │
│     • S-box application                                                           │
│     • Linear layer (MDS matrix multiplication)                                    │
│     • Round constant addition                                                     │
│                                                                                   │
│  These constraints are identical whether the caller interprets the 16 columns as: │
│     • 16 individual base field elements (D=1), or                                 │
│     • 4 extension field elements of degree 4 (D=4)                                │
│                                                                                   │
└───────────────────────────────────────────────────────────────────────────────────┘
</code></pre>
<h2 id="transcript-compatibility"><a class="header" href="#transcript-compatibility">Transcript Compatibility</a></h2>
<p>For recursive verification to be sound, the circuit challenger must produce <strong>identical challenge values</strong> to the native challenger given the same inputs. This requires:</p>
<ol>
<li><strong>Same observation order</strong>: Values must be absorbed in the exact same sequence</li>
<li><strong>Same duplexing triggers</strong>: Permutation must occur at the same points</li>
<li><strong>Same output buffer management</strong>: Samples must come from the same buffer positions</li>
</ol>
<h3 id="extension-field-operations"><a class="header" href="#extension-field-operations">Extension Field Operations</a></h3>
<p>The native challenger provides methods for extension field values:</p>
<div class="table-wrapper"><table><thead><tr><th>Native Method</th><th>Circuit Method</th><th>Behavior</th></tr></thead><tbody>
<tr><td><code>observe_algebra_element(ext)</code></td><td><code>observe_ext(target)</code></td><td>Decompose to D coefficients, observe each</td></tr>
<tr><td><code>sample_algebra_element()</code></td><td><code>sample_ext()</code></td><td>Sample D base elements, recompose</td></tr>
</tbody></table>
</div>
<p>These methods ensure that extension field observations/samples are transcript-compatible.</p>
<p>In addition, when observing opened values in batch verification, we must ensure to respect
the order the native verifier performed for the recursive circuit to be able to satisfy the
associated constraints.</p>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<p>The challenger is configured with a <code>Poseidon2Config</code> that specifies the field and extension degree:</p>
<div class="table-wrapper"><table><thead><tr><th>Config</th><th>Field</th><th>D</th><th>WIDTH</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>BabyBearD4Width16</code></td><td>BabyBear</td><td>4</td><td>16</td><td>Standard recursive verification</td></tr>
<tr><td><code>BabyBearD1Width16</code></td><td>BabyBear</td><td>1</td><td>16</td><td>Base field challenges (lower overhead)</td></tr>
<tr><td><code>BabyBearD4Width24</code></td><td>BabyBear</td><td>4</td><td>24</td><td>Wider configuration, efficient hashing</td></tr>
<tr><td><code>KoalaBearD4Width16</code></td><td>KoalaBear</td><td>4</td><td>16</td><td>Alternative field</td></tr>
<tr><td><code>KoalaBearD1Width16</code></td><td>KoalaBear</td><td>1</td><td>16</td><td>Base field challenges (lower overhead)</td></tr>
<tr><td><code>KoalaBearD4Width24</code></td><td>KoalaBear</td><td>4</td><td>24</td><td>Wider configuration, efficient hashing</td></tr>
</tbody></table>
</div>
<p>The challenger is in charge to validate at runtime that the config matches the extension field being used.</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="scaling-strategies"><a class="header" href="#scaling-strategies">Scaling Strategies</a></h1>
<p>The fixed recursive verifier supports only predetermined programs. This section describes strategies for handling computations of varying size or complexity.</p>
<h2 id="tree-style-recursion-for-variable-length-inputs"><a class="header" href="#tree-style-recursion-for-variable-length-inputs">Tree-style recursion for variable-length inputs</a></h2>
<p>Split a large computation into chunks and prove each chunk independently using a fixed inner circuit. Then aggregate the proofs in a binary tree, where each leaf corresponds to a portion of the computation. The tree root yields a single proof attesting to the entire computation.</p>
<p>This approach is naturally parallelizable: all leaf proofs are independent, and each tree level can be processed in parallel across pairs.</p>
<p>A formal description of tree-style recursion for STARKs can be found in <a href="https://eprint.iacr.org/2023/208">zkTree</a>. See also the <a href="advanced_topics/./aggregation.html">Aggregation</a> chapter for the API.</p>
<h2 id="flexible-fri-verification"><a class="header" href="#flexible-fri-verification">Flexible FRI verification</a></h2>
<p>To support proofs with different FRI shapes (different trace sizes), two techniques apply:</p>
<h3 id="proof-lifting"><a class="header" href="#proof-lifting">Proof lifting</a></h3>
<p><strong>Lift</strong> smaller proofs to a larger domain, as described in <a href="https://hackmd.io/HkfET6x1Qh-yNvm4fKc7zA">Lifting Plonky3</a>. Lifting projects a smaller domain into a larger one, reusing the original LDE and commitments. This lets a fixed circuit verify proofs from a range of trace sizes without recomputation.</p>
<h3 id="multi-shape-fri-verification"><a class="header" href="#multi-shape-fri-verification">Multi-shape FRI verification</a></h3>
<p>Instead of fixing a single proof size per verifier circuit, extend the FRI verifier to handle a <strong>range</strong> of sizes within the same circuit, at minimal overhead. A related approach is implemented in Plonky2 recursion (<a href="https://github.com/0xPolygonZero/plonky2/pull/1635">PR #1635</a>).</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="soundness-and-security"><a class="header" href="#soundness-and-security">Soundness and Security</a></h1>
<p>This section describes the security model, current guarantees, and known limitations.</p>
<h2 id="what-is-proven"><a class="header" href="#what-is-proven">What is proven</a></h2>
<p>A recursive proof attests that:</p>
<ol>
<li>The original computation (base layer) was executed correctly according to the AIR constraints.</li>
<li>Each intermediate STARK verification was performed correctly: commitments were checked, FRI queries were sampled from the transcript, Merkle paths were verified, and polynomial evaluations matched.</li>
<li>The Fiat-Shamir transcript was computed consistently — the circuit challenger produces identical challenges to the native Plonky3 challenger given the same observations.</li>
</ol>
<h2 id="security-parameters"><a class="header" href="#security-parameters">Security parameters</a></h2>
<p>FRI soundness depends on several parameters working together. However, it is not generally correct to
model security as “<code>num_queries × log_blowup</code> bits”. That heuristic relied on strong proximity-gap /
correlated-agreement assumptions that are no longer believed to hold in full generality.
See for instance:</p>
<ul>
<li>https://eprint.iacr.org/2025/2010</li>
<li>https://eprint.iacr.org/2025/2046</li>
</ul>
<p>Instead, the soundness error must be derived from a <em>proven bound</em> for the specific FRI variant
and parameter regime being used.</p>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Role</th></tr></thead><tbody>
<tr><td><code>log_blowup</code></td><td>Sets the Reed–Solomon code rate (blowup factor). This affects the code distance and proximity gap, but does <strong>not</strong> directly translate into a fixed number of “bits per query”.</td></tr>
<tr><td><code>num_queries</code></td><td>Number of independent FRI consistency checks. Increasing this reduces soundness error according to the <em>actual</em> FRI soundness bound being used.</td></tr>
<tr><td><code>query_pow_bits</code></td><td>Proof-of-work grinding. Adds <code>query_pow_bits</code> bits of security independently of the code-theoretic soundness term.</td></tr>
</tbody></table>
</div>
<p>Let:</p>
<pre><code>ε_FRI = soundness error derived from the relevant FRI theorem/bound
        (depends on blowup, proximity parameter δ, domain size,
         field size, and list-decodability/proximity-gap behavior)
</code></pre>
<p>Then the security level should be expressed as:</p>
<pre><code>security ≈ -log2(ε_FRI) + query_pow_bits
</code></pre>
<p>Crucially, <code>-log2(ε_FRI)</code> must be computed from a proven soundness bound for the specific FRI configuration.
It should not be replaced by <code>num_queries × log_blowup</code> unless an additional (explicitly stated)
conjectural assumption is being made.</p>
<h2 id="cryptographic-components-verified-in-circuit"><a class="header" href="#cryptographic-components-verified-in-circuit">Cryptographic components verified in-circuit</a></h2>
<h3 id="merkle-tree-verification"><a class="header" href="#merkle-tree-verification">Merkle tree verification</a></h3>
<p>Every MMCS opening proof (Merkle path) is verified in-circuit via Poseidon2 hashing. The circuit:</p>
<ul>
<li>Hashes sibling pairs up the tree</li>
<li>Checks that the reconstructed root matches the committed root (a public input)</li>
<li>Handles position-dependent ordering (left vs right sibling)</li>
</ul>
<h3 id="fri-verification"><a class="header" href="#fri-verification">FRI verification</a></h3>
<p>The circuit performs the full FRI verification protocol:</p>
<ul>
<li>Samples folding challenges (beta) from the transcript</li>
<li>Samples query indices from the transcript</li>
<li>Verifies proof-of-work witnesses</li>
<li>Checks the fold chain: at each FRI round, verifies that the folded polynomial evaluations are consistent with the committed Merkle trees</li>
<li>Evaluates and checks the final polynomial</li>
</ul>
<h3 id="fiat-shamir-challenger"><a class="header" href="#fiat-shamir-challenger">Fiat-Shamir challenger</a></h3>
<p>The circuit challenger implements a duplex sponge construction identical to Plonky3's native <code>DuplexChallenger</code>. It absorbs commitments and opened values in the same order as the native verifier, producing identical challenges. See <a href="advanced_topics/./hashing.html">Hashing and Fiat-Shamir</a> for details on transcript compatibility.</p>
<h2 id="current-limitations"><a class="header" href="#current-limitations">Current limitations</a></h2>
<h3 id="non-zk-mode-only"><a class="header" href="#non-zk-mode-only">Non-ZK mode only</a></h3>
<p>The library currently supports only non-ZK STARKs (<code>config.is_zk() == 0</code>). The recursive verifier does not handle zero-knowledge randomization of traces.</p>
<h3 id="challenger-poseidon2-ctl-verified"><a class="header" href="#challenger-poseidon2-ctl-verified">Challenger Poseidon2: CTL-verified</a></h3>
<p>The Fiat-Shamir challenger's Poseidon2 permutations are connected to the Poseidon2 AIR table via cross-table lookups (CTLs). The circuit builder's <code>add_poseidon2_perm_for_challenger</code> / <code>add_poseidon2_perm_for_challenger_base</code> use the standard Poseidon2 non-primitive op with full input and rate-output CTL exposure; the executor runs the real permutation and the lookup argument enforces that the (input, output) pair appears in the Poseidon2 table. The MMCS Poseidon2 calls (Merkle verification) are also CTL-verified.</p>
<h3 id="fixed-poseidon2-parameters"><a class="header" href="#fixed-poseidon2-parameters">Fixed Poseidon2 parameters</a></h3>
<p>The recursion stack currently requires <code>WIDTH = 16</code> and <code>RATE = 8</code> for 32-bit fields with degree-4 extensions. Future versions will support configurable parameters.</p>
<h2 id="verifier-trust-model"><a class="header" href="#verifier-trust-model">Verifier trust model</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>How it's verified</th></tr></thead><tbody>
<tr><td>Commitment openings</td><td>Merkle path verification (Poseidon2, CTL-enforced)</td></tr>
<tr><td>FRI fold chain</td><td>Algebraic consistency checks in-circuit</td></tr>
<tr><td>FRI query indices</td><td>Sampled in-circuit from transcript</td></tr>
<tr><td>Proof-of-work</td><td>Verified in-circuit</td></tr>
<tr><td>Fiat-Shamir challenges</td><td>Circuit challenger (CTL-verified against Poseidon2 AIR)</td></tr>
<tr><td>AIR constraint satisfaction</td><td>Evaluated in-circuit via symbolic-to-circuit translation</td></tr>
<tr><td>Lookup argument</td><td>LogUp verification in-circuit</td></tr>
</tbody></table>
</div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="debugging"><a class="header" href="#debugging">Debugging</a></h1>
<p>The <code>CircuitBuilder</code> provides built-in debugging tools to help identify wiring issues and unsatisfied constraints.</p>
<h2 id="allocation-logging"><a class="header" href="#allocation-logging">Allocation Logging</a></h2>
<p>The <code>CircuitBuilder</code> supports an allocation logger during circuit building that logs allocations being performed.
These logs can then be analyzed at runtime and leveraged to detect issues in circuit constructions.</p>
<h3 id="enabling-debug-logging"><a class="header" href="#enabling-debug-logging">Enabling Debug Logging</a></h3>
<p>Allocation logging is automatically enabled in debug builds (or moe generally if <code>debug_assertions</code> are enabled).
Logs can be dumped to <code>stdout</code> when calling <code>builder.dump_allocation_log()</code>, if logging level is set to <code>DEBUG</code> or lower.</p>
<h3 id="allocation-log-format"><a class="header" href="#allocation-log-format">Allocation Log Format</a></h3>
<p>By default, the <code>CircuitBuilder</code> automatically logs all allocations with no specific labels.
One can decide to attach a specific descriptive to ease debugging, like so:</p>
<pre><code class="language-rust ignore">let mut builder = CircuitBuilder::&lt;F&gt;::new();

// Allocating with custom labels
let input_a = builder.alloc_public_input("input_a");
let input_b = builder.alloc_public_input("input_b");
let input_c = builder.alloc_public_input("input_c");

let b_times_c = builder.alloc_mul(input_b, input_c, "b_times_c");
let a_plus_bc = builder.alloc_add(input_a, b_times_c, "a_plus_bc");
let a_minus_bc = builder.alloc_sub(input_a, b_times_c, "a_minus_bc");

// Default allocation
let x = builder.public_input(); // unlabelled
let y = builder.add(x, z);          // unlabelled</code></pre>
<p>The <code>CircuitBuilder</code> also allows for nested scoping of allocation logs, so that users can debug
a specific context within a larger circuit. Scoping can be defined arbitrarily by users as follows:</p>
<pre><code class="language-rust ignore">fn complex_function(builder: &amp;mut CircuitBuilder) {
    builder.push_scope("complex function");

    // Do something
    inner_function(builder); // &lt;- this will create a nested scope within the inner function

    builder.pop_scope();
}

fn inner_function(builder: &amp;mut CircuitBuilder) {
    builder.push_scope("inner function");

    // Do something else

    builder.pop_scope();
}</code></pre>
<h2 id="debugging-constraints"><a class="header" href="#debugging-constraints">Debugging constraints</a></h2>
<p>When debugging constraint satisfaction issues, the system relies on Plonky3's internal <code>check_constraints</code>
feature to evaluate AIR constraints, available in debug mode.
This ensures that all constraints are properly satisfied before proceeding to the next proving phases.</p>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="benchmarks"><a class="header" href="#benchmarks">Benchmarks</a></h1>
<p>This section presents empirical performance results for the Plonky3 recursion system, including instructions for reproducibility across target machines.</p>
<p><strong>NOTE</strong>: This library is still at an early stage, parameters have not been finely tuned yet, and as such performance results here may not reflect the full potential of the library.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<p>The reference examples are a Plonky3 uni-stark proof of the Keccak AIR imported directly, a Plonky3 batch-stark proof of the Fibonacci sequence generated with the <code>CircuitBuilder</code> of this library, and a 2-to-1 aggregation tree over basic <code>p3-batch-stark</code> proofs.</p>
<ul>
<li>Keccak example: set number of hashes with <code>-n</code> argument</li>
</ul>
<pre><code class="language-bash">RUSTFLAGS=-Ctarget-cpu=native RUSTFLAGS=-Copt-level=3 RUST_LOG=info cargo run --release \
    --example recursive_keccak --features parallel -- -n 2500 
</code></pre>
<ul>
<li>Fibonacci example: set element index in the sequence with <code>-n</code> argument</li>
</ul>
<pre><code class="language-bash">RUSTFLAGS=-Ctarget-cpu=native RUSTFLAGS=-Copt-level=3 RUST_LOG=info cargo run --release \
    --example recursive_fibonacci --features parallel -- -n 10000
</code></pre>
<ul>
<li>2-to-1 aggregation example:</li>
</ul>
<pre><code class="language-bash">RUSTFLAGS=-Ctarget-cpu=native RUSTFLAGS=-Copt-level=3 RUST_LOG=info cargo run --release \
    --example recursive_aggregation --features parallel -- --field koala-bear
</code></pre>
<h3 id="parameterization"><a class="header" href="#parameterization">Parameterization</a></h3>
<p>Each example supports additional parameterization around the FRI parameters, namely:</p>
<ul>
<li><code>--log-blowup</code>: logarithmic blowup factor for the LDE. Default 3.</li>
<li><code>--max-log-arity</code>: maximum arity allowed during the FRI folding phases. Default 4.</li>
<li><code>--log-final-poly-len</code>: logarithmic size (or degree) allowed for the final polynomial after folding. Default 5.</li>
<li><code>--cap-height</code>: the height at which the MMCS tree is truncated for commitments. Default 0 (unique root).</li>
<li><code>--commit-pow-bits</code>: additional PoW grinding during the FRI commit phase. Default 0.</li>
<li><code>--query-pow-bits</code>: additional PoW grinding during the FRI query phase. Default 16.</li>
<li><code>--num-recursive-layers</code>: number of recursive proofs to be generated in a chain, starting from the base proof (Keccak or Fibonacci). Default 3.</li>
<li><code>--witness-lanes</code>: number of witness lanes for the table packing in recursive layers. Default varies per examples.</li>
<li><code>--public-lanes</code>: number of public lanes for the table packing in recursive layers. Default varies per examples.</li>
<li><code>--alu-lanes</code>: number of ALU lanes for the table packing in recursive layers. Default varies per examples.</li>
</ul>
<h2 id="results"><a class="header" href="#results">Results</a></h2>
<p>Running on a Apple M4 pro, 14 Cores, with <strong>KoalaBear</strong> field and extension of <strong>degree 4</strong>, using default parameters mentioned above, performance benchmarks are as follows:</p>
<ul>
<li>
<p><strong>Keccak AIR program:</strong> (1,000 hashes)</p>
<ul>
<li>Base uni-stark proof: 1.44 s</li>
<li>1st recursion layer: 2.71 s</li>
<li>2nd recursion layer: 374 ms</li>
<li>3rd recursion layer: 372 ms</li>
</ul>
</li>
<li>
<p><strong>Fibonacci multi-AIR program:</strong> (10,000th element)</p>
<ul>
<li>Base batch-stark proof: 86.1 ms</li>
<li>1st recursion layer: 243 ms</li>
<li>2nd recursion layer: 415 ms</li>
<li>3rd recursion layer: 393 ms</li>
</ul>
</li>
<li>
<p><strong>2-to-1 aggregation:</strong></p>
<ul>
<li>Base batch-stark proof: 30 ms</li>
<li>1st aggregation layer: 431 ms</li>
<li>2nd aggregation layer: 825 ms</li>
<li>3rd and next aggregation layers: 806 ms</li>
</ul>
</li>
</ul>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="roadmap"><a class="header" href="#roadmap">Roadmap</a></h1>
<p>This page tracks planned improvements and known optimization opportunities.</p>
<h2 id="soundness"><a class="header" href="#soundness">Soundness</a></h2>
<ul>
<li><strong>ZK mode</strong>: Support zero-knowledge STARKs (trace randomization). Currently only non-ZK mode is supported.</li>
</ul>
<h2 id="performance"><a class="header" href="#performance">Performance</a></h2>
<ul>
<li><strong>Eliminate decompose/recompose round-trips</strong>: Base field values are currently lifted to extension field targets and then repacked before MMCS verification, which decomposes them again. Keeping values in base coefficient form throughout would eliminate ~15-20% of circuit operations.</li>
<li><strong>Dedicated FRI AIR table</strong>: A specialized non-primitive chip for Lagrange interpolation during FRI folding would offload ~30K primitive operations to a compact AIR.</li>
<li><strong>Remove the Witness bus</strong>: Since the verifier program is fixed and deterministic, the global Witness table can be replaced with direct inter-chip lookups, eliminating an entire table.</li>
<li><strong>Additional optimization passes</strong>: More aggressive dead-node pruning, common subexpression elimination, and chain fusion in the circuit optimizer.</li>
</ul>
<h2 id="flexibility"><a class="header" href="#flexibility">Flexibility</a></h2>
<ul>
<li><strong>Configurable WIDTH/RATE</strong>: Currently fixed at <code>WIDTH=16</code>, <code>RATE=8</code> for 32-bit fields. Making these configurable would support wider permutations and different security/performance trade-offs.</li>
<li><strong>Goldilocks support</strong>: Full testing and optimization for the 64-bit Goldilocks field.</li>
<li><strong>Multi-shape FRI verification</strong>: A single verifier circuit that can handle proofs with different trace sizes, reducing the need for proof lifting.</li>
</ul>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<p><strong>AIR</strong> — Algebraic Intermediate Representation. A set of polynomial constraints that define the validity of an execution trace. Each row of the trace must satisfy the AIR's constraints.</p>
<p><strong>ALU</strong> — Arithmetic Logic Unit. In this library, the primitive chip that handles <code>add</code>, <code>mul</code>, <code>sub</code>, <code>div</code>, <code>bool_check</code>, and <code>mul_add</code> operations via selector columns.</p>
<p><strong>CTL</strong> — Cross-Table Lookup. A mechanism to enforce consistency between different AIR tables by proving that multisets of tuples match across tables. Uses the LogUp argument.</p>
<p><strong>D</strong> — Extension field degree. The recursion stack uses degree-4 extensions (<code>D = 4</code>), meaning each extension field element is represented by 4 base field elements.</p>
<p><strong>FRI</strong> — Fast Reed-Solomon Interactive Oracle Proof. The polynomial commitment scheme used by Plonky3. Proves that a committed function is close to a low-degree polynomial via iterative folding and random queries.</p>
<p><strong>IR</strong> — Intermediate Representation. The deterministic sequence of operations (constants, public inputs, arithmetic, non-primitives) that defines a circuit's computation.</p>
<p><strong>LDE</strong> — Low-Degree Extension. Evaluating a polynomial on a domain larger than its degree, used to create redundancy for FRI queries. The blowup factor controls the domain expansion ratio.</p>
<p><strong>LogUp</strong> — Logarithmic derivative lookup argument. The specific lookup protocol used to enforce CTL relations between tables. Based on <a href="https://eprint.iacr.org/2022/1530">Ulrich Haböck's construction</a>.</p>
<p><strong>MMCS</strong> — Mixed Matrix Commitment Scheme. Plonky3's abstraction for committing to matrices of field elements. Typically instantiated with Merkle trees over Poseidon2 hashes.</p>
<p><strong>PCS</strong> — Polynomial Commitment Scheme. A cryptographic primitive that allows committing to a polynomial and later proving evaluations at chosen points. FRI is the PCS used here.</p>
<p><strong>Poseidon2</strong> — An algebraic hash function optimized for arithmetic circuits. Used for Merkle tree hashing and Fiat-Shamir challenges. Parameterized by WIDTH (number of state elements) and RATE (elements absorbed per permutation).</p>
<p><strong>RAP</strong> — Randomized AIR with Preprocessing. An extension of AIR that supports preprocessed columns (known to the verifier before the proof) and randomized columns (computed after an initial commitment round).</p>
<p><strong>STARK</strong> — Scalable Transparent Argument of Knowledge. A proof system based on polynomial IOPs and hash functions (no trusted setup). Plonky3 implements uni-STARKs (single AIR) and batch-STARKs (multiple AIRs with shared FRI).</p>
<p><strong>Target</strong> — An identifier for a value in the circuit's expression graph. Each <code>Target</code> (also called <code>ExprId</code>) refers to either a constant, a public input, or the output of an operation.</p>
<p><strong>WitnessId</strong> — An index into the global Witness table. After circuit compilation, each <code>Target</code> is assigned a <code>WitnessId</code> that identifies its slot in the witness memory bus.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
